@misc{zeng2024flightllm,
    title={FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs}, 
    author={Shulin Zeng and Jun Liu and Guohao Dai and Xinhao Yang and Tianyu Fu and Hongyi Wang and Wenheng Ma and Hanbo Sun and Shiyao Li and Zixiao Huang and Yadong Dai and Jintao Li and Zehao Wang and Ruoyu Zhang and Kairui Wen and Xuefei Ning and Yu Wang},
    year={2024},
    eprint={2401.03868},
    archivePrefix={arXiv},
    primaryClass={cs.AR}
}
@inproceedings{rpython,
 	author = {Ancona, Davide and Ancona, Massimo and Cuni, Antonio and Matsakis, Nicholas D.},
 	title = {RPython: a step towards reconciling dynamically and statically typed OO languages},
 	booktitle = {DLS '07: Proceedings of the 2007 symposium on Dynamic languages},
 	year = {2007},
 	isbn = {978-1-59593-868-8},
 	pages = {53--64},
 	location = {Montreal, Quebec, Canada},
 	doi = {http://doi.acm.org/10.1145/1297081.1297091},
 	publisher = {ACM},
 	address = {New York, NY, USA},
}
@inproceedings{pypy1,
author = {Bolz, Carl Friedrich and Cuni, Antonio and Fijalkowski, Maciej and Rigo, Armin},
title = {Tracing the meta-level: PyPy's tracing JIT compiler},
year = {2009},
isbn = {9781605585413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1565824.1565827},
doi = {10.1145/1565824.1565827},
abstract = {We attempt to apply the technique of Tracing JIT Compilers in the context of the PyPy project, i.e., to programs that are interpreters for some dynamic languages, including Python. Tracing JIT compilers can greatly speed up programs that spend most of their time in loops in which they take similar code paths. However, applying an unmodified tracing JIT to a program that is itself a bytecode interpreter results in very limited or no speedup. In this paper we show how to guide tracing JIT compilers to greatly improve the speed of bytecode interpreters. One crucial point is to unroll the bytecode dispatch loop, based on two kinds of hints provided by the implementer of the bytecode interpreter. We evaluate our technique by applying it to two PyPy interpreters: one is a small example, and the other one is the full Python interpreter.},
booktitle = {Proceedings of the 4th Workshop on the Implementation, Compilation, Optimization of Object-Oriented Languages and Programming Systems},
pages = {18–25},
numpages = {8},
location = {Genova, Italy},
series = {ICOOOLPS '09}
}
@misc{izawa2022threaded,
      title={Threaded Code Generation with a Meta-Tracing JIT Compiler}, 
      author={Yusuke Izawa and Hidehiko Masuhara and Carl Friedrich Bolz-Tereick and Youyou Cong},
      year={2022},
      eprint={2106.12496},
      archivePrefix={arXiv},
      primaryClass={cs.PL}
}
@inproceedings{pypy2,
 author = {Rigo, Armin and Pedroni, Samuele},
 title = {PyPy's approach to virtual machine construction},
 booktitle = {OOPSLA '06: Companion to the 21st ACM SIGPLAN symposium on Object-oriented programming systems, languages, and applications},
 year = {2006},
 isbn = {1-59593-491-X},
 pages = {944--953},
 location = {Portland, Oregon, USA},
 doi = {http://doi.acm.org/10.1145/1176617.1176753},
 publisher = {ACM},
 address = {New York, NY, USA},
 }
@Article{harris2020array,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
                 R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}
@ARTICLE{cython,
  author={Behnel, Stefan and Bradshaw, Robert and Citro, Craig and Dalcin, Lisandro and Seljebotn, Dag Sverre and Smith, Kurt},
  journal={Computing in Science & Engineering}, 
  title={Cython: The Best of Both Worlds}, 
  year={2011},
  volume={13},
  number={2},
  pages={31-39},
  keywords={Sparse matrices;Runtime;Syntactics;Computer programs;Programming;Python;Cython;numerics;scientific computing},
  doi={10.1109/MCSE.2010.118}}
@INPROCEEDINGS{pypy3,
  author={During, B.},
  booktitle={AGILE 2006 (AGILE'06)}, 
  title={Trouble in paradise: the open source project PyPy, EU-funding and agile practices}, 
  year={2006},
  volume={},
  number={},
  pages={11 pp.-231},
  keywords={Collaborative work;Open source software;Project management;Programming;Collaborative software;Testing},
  doi={10.1109/AGILE.2006.58}}
@article{jit,
author = {Phogat, Sandeep},
year = {2013},
month = {07},
pages = {},
title = {INTRODUCTION TO JIT: A REVIEW},
volume = {2},
journal = {International Journal of Latest Research in Science and Technology}
}
@article{hlsintro,
author = {Coussy, Philippe and Gajski, Daniel and Meredith, Michael and Takach, Andres},
year = {2009},
month = {09},
pages = {8 - 17},
title = {An Introduction to High-Level Synthesis},
volume = {26},
journal = {Design & Test of Computers, IEEE},
doi = {10.1109/MDT.2009.69}
}
@INPROCEEDINGS{dsl1,
  author={George, Nithin and Lee, HyoukJoong and Novo, David and Rompf, Tiark and Brown, Kevin J. and Sujeeth, Arvind K. and Odersky, Martin and Olukotun, Kunle and Ienne, Paolo},
  booktitle={2014 24th International Conference on Field Programmable Logic and Applications (FPL)}, 
  title={Hardware system synthesis from Domain-Specific Languages}, 
  year={2014},
  volume={},
  number={},
  pages={1-8},
  keywords={Hardware;Kernel;Optimization;DSL;Field programmable gate arrays;Data structures;Parallel processing},
  doi={10.1109/FPL.2014.6927454}}
@article{halide,
author = {Ragan-Kelley, Jonathan and Adams, Andrew and Sharlet, Dillon and Barnes, Connelly and Paris, Sylvain and Levoy, Marc and Amarasinghe, Saman and Durand, Fr\'{e}do},
title = {Halide: decoupling algorithms from schedules for high-performance image processing},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {61},
number = {1},
issn = {0001-0782},
url = {https://doi.org/10.1145/3150211},
doi = {10.1145/3150211},
abstract = {Writing high-performance code on modern machines requires not just locally optimizing inner loops, but globally reorganizing computations to exploit parallelism and locality---doing things such as tiling and blocking whole pipelines to fit in cache. This is especially true for image processing pipelines, where individual stages do much too little work to amortize the cost of loading and storing results to and from off-chip memory. As a result, the performance difference between a naive implementation of a pipeline and one globally optimized for parallelism and locality is often an order of magnitude. However, using existing programming tools, writing high-performance image processing code requires sacrificing simplicity, portability, and modularity. We argue that this is because traditional programming models conflate the computations defining the algorithm with decisions about intermediate storage and the order of computation, which we call the schedule.We propose a new programming language for image processing pipelines, called Halide, that separates the algorithm from its schedule. Programmers can change the schedule to express many possible organizations of a single algorithm. The Halide compiler then synthesizes a globally combined loop nest for an entire algorithm, given a schedule. Halide models a space of schedules which is expressive enough to describe organizations that match or outperform state-of-the-art hand-written implementations of many computational photography and computer vision algorithms. Its model is simple enough to do so often in only a few lines of code, and small changes generate efficient implementations for x86, ARM, Graphics Processors (GPUs), and specialized image processors, all from a single algorithm.Halide has been public and open source for over four years, during which it has been used by hundreds of programmers to deploy code to tens of thousands of servers and hundreds of millions of phones, processing billions of images every day.},
journal = {Commun. ACM},
month = {dec},
pages = {106–115},
numpages = {10}
}
@inproceedings{bluespec,
author = {Bourgeat, Thomas and Pit-Claudel, Cl\'{e}ment and Chlipala, Adam and Arvind},
title = {The essence of Bluespec: a core language for rule-based hardware design},
year = {2020},
isbn = {9781450376136},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3385412.3385965},
doi = {10.1145/3385412.3385965},
abstract = {The Bluespec hardware-description language presents a significantly higher-level view than hardware engineers are used to, exposing a simpler concurrency model that promotes formal proof, without compromising on performance of compiled circuits. Unfortunately, the cost model of Bluespec has been unclear, with performance details depending on a mix of user hints and opaque static analysis of potential concurrency conflicts within a design. In this paper we present Koika, a derivative of Bluespec that preserves its desirable properties and yet gives direct control over the scheduling decisions that determine performance. Koika has a novel and deterministic operational semantics that uses dynamic analysis to avoid concurrency anomalies. Our implementation includes Coq definitions of syntax, semantics, key metatheorems, and a verified compiler to circuits. We argue that most of the extra circuitry required for dynamic analysis can be eliminated by compile-time BSV-style static analysis.},
booktitle = {Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {243–257},
numpages = {15},
keywords = {Compiler Correctness, Hardware Description Language, Semantics},
location = {London, UK},
series = {PLDI 2020}
}
@inproceedings{spatial,
author = {Koeplinger, David and Feldman, Matthew and Prabhakar, Raghu and Zhang, Yaqi and Hadjis, Stefan and Fiszel, Ruben and Zhao, Tian and Nardi, Luigi and Pedram, Ardavan and Kozyrakis, Christos and Olukotun, Kunle},
title = {Spatial: a language and compiler for application accelerators},
year = {2018},
isbn = {9781450356985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3192366.3192379},
doi = {10.1145/3192366.3192379},
abstract = {Industry is increasingly turning to reconfigurable architectures like FPGAs and CGRAs for improved performance and energy efficiency. Unfortunately, adoption of these architectures has been limited by their programming models. HDLs lack abstractions for productivity and are difficult to target from higher level languages. HLS tools are more productive, but offer an ad-hoc mix of software and hardware abstractions which make performance optimizations difficult.  In this work, we describe a new domain-specific language and compiler called Spatial for higher level descriptions of application accelerators. We describe Spatial's hardware-centric abstractions for both programmer productivity and design performance, and summarize the compiler passes required to support these abstractions, including pipeline scheduling, automatic memory banking, and automated design tuning driven by active machine learning. We demonstrate the language's ability to target FPGAs and CGRAs from common source code. We show that applications written in Spatial are, on average, 42\% shorter and achieve a mean speedup of 2.9x over SDAccel HLS when targeting a Xilinx UltraScale+ VU9P FPGA on an Amazon EC2 F1 instance.},
booktitle = {Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {296–311},
numpages = {16},
keywords = {reconfigurable architectures, high-level synthesis, hardware accelerators, domain-specific languages, compilers, FPGAs, CGRAs},
location = {Philadelphia, PA, USA},
series = {PLDI 2018}
}
@inproceedings{heterocl,
author = {Lai, Yi-Hsiang and Chi, Yuze and Hu, Yuwei and Wang, Jie and Yu, Cody Hao and Zhou, Yuan and Cong, Jason and Zhang, Zhiru},
title = {HeteroCL: A Multi-Paradigm Programming Infrastructure for Software-Defined Reconfigurable Computing},
year = {2019},
isbn = {9781450361378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3289602.3293910},
doi = {10.1145/3289602.3293910},
abstract = {With the pursuit of improving compute performance under strict power constraints, there is an increasing need for deploying applications to heterogeneous hardware architectures with accelerators, such as GPUs and FPGAs. However, although these heterogeneous computing platforms are becoming widely available, they are very difficult to program especially with FPGAs. As a result, the use of such platforms has been limited to a small subset of programmers with specialized hardware knowledge. To tackle this challenge, we introduce HeteroCL, a programming infrastructure composed of a Python-based domain-specific language (DSL) and an FPGA-targeted compilation flow. The HeteroCL DSL provides a clean programming abstraction that decouples algorithm specification from three important types of hardware customization in compute, data types, and memory architectures. HeteroCL further captures the interdependence among these different customization techniques, allowing programmers to explore various performance/area/accuracy trade-offs in a systematic and productive manner. In addition, our framework produces highly efficient hardware implementations for a variety of popular workloads by targeting spatial architecture templates such as systolic arrays and stencil with dataflow architectures. Experimental results show that HeteroCL allows programmers to explore the design space efficiently in both performance and accuracy by combining different types of hardware customization and targeting spatial architectures, while keeping the algorithm code intact.},
booktitle = {Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
pages = {242–251},
numpages = {10},
keywords = {compiler, domain-specific language, fpga, hardware accelerator, high-level synthesis, multi-paradigm programming, python, reconfigurable computing, spatial architecture, stencil, systolic array},
location = {Seaside, CA, USA},
series = {FPGA '19}
}
@INPROCEEDINGS{hls,
  author={Ren, Haoxing},
  booktitle={2014 IEEE International Conference on IC Design & Technology}, 
  title={A brief introduction on contemporary High-Level Synthesis}, 
  year={2014},
  volume={},
  number={},
  pages={1-4},
  keywords={Hardware;Algorithm design and analysis;Timing;Optimization;Software;Field programmable gate arrays;Pipeline processing;High-Level Synthesis},
  doi={10.1109/ICICDT.2014.6838614}}
@inproceedings{bytecode,
  title={Byte Code Engineering},
  author={Markus Dahm},
  booktitle={Java-Informations-Tage},
  year={1999},
  url={https://api.semanticscholar.org/CorpusID:5333101}
}
@misc{scalehls,
      title={ScaleHLS: A New Scalable High-Level Synthesis Framework on Multi-Level Intermediate Representation}, 
      author={Hanchen Ye and Cong Hao and Jianyi Cheng and Hyunmin Jeong and Jack Huang and Stephen Neuendorffer and Deming Chen},
      year={2021},
      eprint={2107.11673},
      archivePrefix={arXiv},
      primaryClass={cs.PL}
}
@misc{mlir,
      title={MLIR: A Compiler Infrastructure for the End of Moore's Law}, 
      author={Chris Lattner and Mehdi Amini and Uday Bondhugula and Albert Cohen and Andy Davis and Jacques Pienaar and River Riddle and Tatiana Shpeisman and Nicolas Vasilache and Oleksandr Zinenko},
      year={2020},
      eprint={2002.11054},
      archivePrefix={arXiv},
      primaryClass={cs.PL}
}
@inproceedings{muir,
author = {Sharifian, Amirali and Hojabr, Reza and Rahimi, Navid and Liu, Sihao and Guha, Apala and Nowatzki, Tony and Shriraman, Arrvindh},
title = {μIR -An intermediate representation for transforming and optimizing the microarchitecture of application accelerators},
year = {2019},
isbn = {9781450369381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3352460.3358292},
doi = {10.1145/3352460.3358292},
abstract = {Creating high quality application-specific accelerators requires us to make iterative changes to both algorithm behavior and microarchitecture, and this is a tedious and error-prone process. High-Level Synthesis (HLS) tools [5, 10] generate RTL for application accelerators from annotated software. Unfortunately, the generated RTL is challenging to change and optimize. The primary limitation of HLS is that the functionality and microarchitecture are conflated together in a single language (such as C++). Making changes to the accelerator design may require code restructuring, and microarchitecture optimizations are tied with program correctness.We propose a generalized intermediate representation for describing accelerator microarchitecture, μIR, and an associated pass framework, μopt. μIR represents the accelerator as a concurrent structural graph in which the components roughly correspond to microarchitecture level hardware blocks (e.g., function units, network, memory banks). There are two important benefits i) it decouples microarchitecture optimizations from algorithm/program optimizations. ii) it decouples microarchitecture optimizations from the RTL generation. Computer architects express their ideas as a set of iterative transformations of the μIR graph that successively refine the accelerator architecture. The μIR graph is then translated to Chisel, while maintaining the execution model and cycle-level performance characteristics. In this paper, we study three broad classes of optimizations: Timing (e.g., Pipeline re-timing), Spatial (e.g., Compute tiling), and Higher-order Ops (e.g., Tensor function units) that deliver between 1.5 --- 8\texttimes{} improvement in performance; overall 5---20\texttimes{} speedup compared to an ARM A9 1Ghz. We evaluate the quality of the autogenerated accelerators on an Arria 10 FPGA and under ASIC UMC 28nm technology.},
booktitle = {Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {940–953},
numpages = {14},
location = {Columbus, OH, USA},
series = {MICRO '52}
}
@INPROCEEDINGS{spark,
  author={Gupta, S. and Dutt, N. and Gupta, R. and Nicolau, A.},
  booktitle={16th International Conference on VLSI Design, 2003. Proceedings.}, 
  title={SPARK: a high-level synthesis framework for applying parallelizing compiler transformations}, 
  year={2003},
  volume={},
  number={},
  pages={461-466},
  keywords={Sparks;High level synthesis;Resource management;Hardware;Costs;Design optimization;Optimizing compilers;Job shop scheduling;Dynamic scheduling;Image processing},
  doi={10.1109/ICVD.2003.1183177}}
@INPROCEEDINGS{cirrf,
  author={Guo, Zhi and Najjar, Walid},
  booktitle={2006 International Conference on Field Programmable Logic and Applications}, 
  title={A Compiler Intermediate Representation for Reconfigurable Fabrics}, 
  year={2006},
  volume={},
  number={},
  pages={1-4},
  keywords={Fabrics;Hardware;Pipeline processing;Field programmable gate arrays;High level synthesis;High level languages;Java;Timing;Flow graphs;Assembly},
  doi={10.1109/FPL.2006.311304}}
